head(SA)
SA.logit <- glm(chd ~ ., data = SA, family = "binomial")
# c)
summary(SA.logit)
# d)
exp(as.numeric(coef(SA.logit)["age"]))
coef(SA.logit)
library(ggplot2)
dane <- read.table("http://www.ipipan.eu/~teisseyrep/TEACHING/ZMUM/DANE/earthquake.txt", h = T)
#Wykres:
ggplot(data = dane, aes(x = body, y = surface, col = popn))+
geom_point(size = 2.5) +
theme(axis.title.x = element_text(size = 15, angle = 0, face = "italic"),
axis.title.y = element_text(size = 15, angle = 90, face = "italic")) +
theme(legend.title = element_text(size = 14, face = "bold")) +
theme(legend.text = element_text(colour = "black", size = 12)) +
guides(color = guide_legend(keywidth = 2, keyheight = 2))
dane <- read.table("http://www.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/earthquake.txt", h = T)
dane <- read.table("http://www.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/Zadania/earthquake.txt", h = T)
dane <- read.table("http://www.home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/Zadania/earthquake.txt", h = T)
dane <- read.table("http://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/Zadania/earthquake.txt", h = T)
dane <- read.table("https://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/earthquake.txt", h = T)
#Wykres:
ggplot(data = dane, aes(x = body, y = surface, col = popn))+
geom_point(size = 2.5) +
theme(axis.title.x = element_text(size = 15, angle = 0, face = "italic"),
axis.title.y = element_text(size = 15, angle = 90, face = "italic")) +
theme(legend.title = element_text(size = 14, face = "bold")) +
theme(legend.text = element_text(colour = "black", size = 12)) +
guides(color = guide_legend(keywidth = 2, keyheight = 2))
# z powyzszego wykresu widac, ze klasy w tych danych sa liniowo separo
model <- glm(popn ~ ., data = dane, family = "binomial")
summary(model)
# c)
summary(SA.logit)
# e)
SA.logit.aic <- step(SA.logit, direction = "backward", k = 2) # selekcja z uzyciem kryterium AIC
summary(SA.logit.aic)
?step
SA.logit$coefficients
SA.logit$fitted.values
exp(1.969)
exp(-1.969)
1 / (1 + exp(-1.969))
SA.logit$fitted.values[1]
# c)
summary(SA.logit)
SA.logit$residuals
SA.logit$residuals[1]
SA[1]
SA.logit$residuals[1]
SA.logit$residuals[1,]
SA[1,]
SA.logit$fitted.values[1]
SA.logit$linear.predictors[1]
?glm
exp(-1.969)
exp(-0.9060095)
SA[2]
SA[2,]
SA[3,]
SA.logit$residuals[3]
SA.logit$fitted.values[3]
SA.logit$linear.predictors[3]
exp(0.9397)
exp(0.9397194)
rm(list = ls())
console <- c("Nintendo Switch", "PlayStation 4", "Nintendo 3DS", "PS Vita", "Xbox One")
consoles_sold <- c(3482388, 1695227, 566420, 181728, 15339)
df <- data.frame(console, consoles_sold)
df <- df[order(df$consoles_sold), c(1,2)]
ggplot(df, aes(x=reorder(console, -consoles_sold), y=consoles_sold, label = consoles_sold)) +
geom_bar(stat="identity", fill='darkblue') +
ggtitle("Sprzedaż konsoli w Japonii w 2018 r.") +
labs(y="Liczba sprzedanych konsoli", x = "Konsola") +
scale_y_continuous(labels = scales::format_format(big.mark = " ", decimal.mark = ",", scientific = FALSE)) +
geom_text(size = 4, position = position_dodge(width = 1), vjust = -0.4) +
theme_bw()
library(gridSVG)
install.packages("gridSVG")
plt <- ggplot(df, aes(x=reorder(console, -consoles_sold), y=consoles_sold, label = consoles_sold)) +
geom_bar(stat="identity", fill='darkblue') +
ggtitle("Sprzedaż konsoli w Japonii w 2018 r.") +
labs(y="Liczba sprzedanych konsoli", x = "Konsola") +
scale_y_continuous(labels = scales::format_format(big.mark = " ", decimal.mark = ",", scientific = FALSE)) +
geom_text(size = 4, position = position_dodge(width = 1), vjust = -0.4) +
theme_bw()
svg("learning-inkscape.svg", height = 7.5, width = 8)
plt
dev.off()
library(ggplot2)
dane <- read.table("https://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/earthquake.txt", h = T)
#Wykres:
ggplot(data = dane, aes(x = body, y = surface, col = popn))+
geom_point(size = 2.5) +
theme(axis.title.x = element_text(size = 15, angle = 0, face = "italic"),
axis.title.y = element_text(size = 15, angle = 90, face = "italic")) +
theme(legend.title = element_text(size = 14, face = "bold")) +
theme(legend.text = element_text(colour = "black", size = 12)) +
guides(color = guide_legend(keywidth = 2, keyheight = 2))
SA.logit.aic <- step(SA.logit, direction = "backward", k = 2) # selekcja z uzyciem kryterium AIC
summary(SA.logit.aic)
SA.logit.bic <- step(SA.logit, direction = "backward", k = log(nrow(SA))) # selekcja z uzyciem kryterium BIC
summary(SA.logit.bic)
# e)
SA.logit.aic <- step(SA.logit, direction = "backward", k = 2) # selekcja z uzyciem kryterium AIC
###############################################
############ REGRESJA LOGISTYCZNA #############
###############################################
###### ZADANIE 1 #######
SA <- read.table("https://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/SAheart.data", sep = ",", h = T)
# a)
# X = 1 (chd = 1), X = 0 (chd = 0)
# Y = 1 (famhist = present), Y = 0 (famhist = absent)
#      X = 1     X = 0
# Y=1  p11        p10
# Y=0  p01        p00
# OR = (p11p00)/(p01p10)
n <- nrow(SA)
n11 <- sum(SA$chd == 1 & SA$famhist == "Present")
n10 <- sum(SA$chd == 0 & SA$famhist == "Present")
n01 <- sum(SA$chd == 1 & SA$famhist == "Absent")
n00 <- sum(SA$chd == 0 & SA$famhist == "Absent")
# p11 = n11/n
# p10 = n10/n
# p01 = n01/n
# p00 = n00/n
# wyznaczamy iloraz szans dla zmiennych famhist i chd
OR <- (n11*n00)/(n01*n10)
OR
# b)
SA <- SA[,-1]
SA.logit <- glm(chd ~ ., data = SA, family = "binomial")
# c)
summary(SA.logit)
# d)
exp(as.numeric(coef(SA.logit)["age"]))
# e)
SA.logit.aic <- step(SA.logit, direction = "backward", k = 2) # selekcja z uzyciem kryterium AIC
summary(SA.logit.aic)
SA.logit.bic <- step(SA.logit, direction = "backward", k = log(nrow(SA))) # selekcja z uzyciem kryterium BIC
summary(SA.logit.bic)
library(ggplot2)
dane <- read.table("https://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/earthquake.txt", h = T)
#Wykres:
ggplot(data = dane, aes(x = body, y = surface, col = popn))+
geom_point(size = 2.5) +
theme(axis.title.x = element_text(size = 15, angle = 0, face = "italic"),
axis.title.y = element_text(size = 15, angle = 90, face = "italic")) +
theme(legend.title = element_text(size = 14, face = "bold")) +
theme(legend.text = element_text(colour = "black", size = 12)) +
guides(color = guide_legend(keywidth = 2, keyheight = 2))
# z powyzszego wykresu widac, ze klasy w tych danych sa liniowo separowalne
model <- glm(popn ~ ., data = dane, family = "binomial")
summary(model)
L = 50 #liczba symulacji
N = seq(from=50,to=300,by=10)
MSE = numeric(length(N))
i=1
for(n in N){
cat("Simulation for n=",n,"\n")
mse = numeric(L)
for(k in 1:L){
x1 = rnorm(n,0,1)
x2 = rnorm(n,0,1)
Beta = c(0.5,1,1)
z =  Beta[1] + Beta[2]*x1 +Beta[3]*x2
p = 1/(1+exp(-z))
y = rbinom(n,1,p)
model = glm(y~x1+x2,family="binomial")
Beta_Hat = as.numeric(model$coef)
mse[k] =   sum((Beta_Hat-Beta)^2)
}
MSE[i] = mean(mse)
i=i+1
}
plot(N,MSE,type="b",col="red")
?rbinom
load("~/R files/Machine Learning/Projekt1 - Klasyfikatory/.RData")
dat_new
numeric_data
dat_new$Var44[1,1]
dat_new$Var44[1]
dat_new$Var44[1] == ""
normalize <- function(x, median = TRUE, t = 0.03) {
if (median == TRUE) {
x[is.na(x) || x == ""] <- median(x[!is.na(x)]) #ewentualnie dac srednia
} else
{
x[is.na(x) || x == ""] <- mean(x[!is.na(x)], trim = t)
}
x <- x / max(x)
return(x)
}
to_normalize <- c(1,3,4,5,10,12,13,18,20,23,26,27,29,32,33,34,37,38,40)
to_factorize <- c(2, 9, 11, 14, 15, 19, 31, 35, 36, 41, 42, 44)
to_rethink <- setdiff(1:44, c(to_normalize, to_factorize))
to_rethink
SA <- read.table("https://home.ipipan.waw.pl/p.teisseyre/TEACHING/ZMUM/DANE/SAheart.data", h = T, row.names = 1, sep = ",")
SA
# b)
SA <- SA[,-1]
SA
SA.logit <- glm(chd ~ ., data = SA, family = "binomial")
# c)
summary(SA.logit)
class(SA$famhist)
shiny::runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
?element_text
runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
runApp('Shiny_application')
getwd()
length(s)
:
:
s = 'text = \"Epoch {}/{} loss on test: {:6.5f}, acc on test: {:5.4f}, loss on train: {:6.5f}, acc on train: {:5.4f}".format(epoch, epochs, test_loss, test_acc, train_loss, train_acc)'
length(s)
nchar(s)
rm(list = ls())
list_of_variables = list(".date", ".to", ".from", ".legPrice", ".time," ,".tp", "p")
#wczytanie danych
library(rvest)
loty <- read_html("http://www.azair.eu/azfin.php?searchtype=flexi&tp=0&isOneway=return&srcAirport=Wroclaw+%5BWRO%5D+%28%2BPOZ%2CKTW%2CPRG%2CKRK%29&srcap1=POZ&srcap2=KTW&srcap5=PRG&srcap9=KRK&srcFreeAirport=&srcTypedText=pra&srcFreeTypedText=&srcMC=&dstAirport=Milan+%5BMXP%5D+%28%2BLIN%2CBGY%29&dstap0=LIN&dstap1=BGY&dstFreeAirport=&dstTypedText=mil&dstFreeTypedText=&dstMC=MIL_ALL&depmonth=201903&depdate=2019-03-20&aid=0&arrmonth=202003&arrdate=2020-03-19&minDaysStay=5&maxDaysStay=8&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&samedep=true&samearr=true&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&autoprice=true&adults=1&children=0&infants=0&maxChng=1&currency=EUR&indexSubmit=Search")
all <- html_text(html_nodes(loty, "p")) #cos z list_of_variables
# Podgląd elementów
all[1]
all[2]
all[3]
loty <- read_html("http://www.azair.eu/azfin.php?searchtype=flexi&tp=0&isOneway=return&srcAirport=Wroclaw+%5BWRO%5D+%28%2BPOZ%2CKTW%2CPRG%2CKRK%29&srcap1=POZ&srcap2=KTW&srcap5=PRG&srcap9=KRK&srcFreeAirport=&srcTypedText=pra&srcFreeTypedText=&srcMC=&dstAirport=Milan+%5BMXP%5D+%28%2BLIN%2CBGY%29&dstap0=LIN&dstap1=BGY&dstFreeAirport=&dstTypedText=mil&dstFreeTypedText=&dstMC=MIL_ALL&depmonth=201904&depdate=2019-04-23&aid=0&arrmonth=202003&arrdate=2020-03-31&minDaysStay=5&maxDaysStay=8&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&samedep=true&samearr=true&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&autoprice=true&adults=1&children=0&infants=0&maxChng=1&currency=EUR&indexSubmit=Search")
all <- html_text(html_nodes(loty, "p")) #cos z list_of_variables
all <- html_text(html_nodes(loty, "text")) #cos z list_of_variables
# Podgląd elementów
all[1]
all <- html_text(html_nodes(loty, ".text")) #cos z list_of_variables
all
all[1]
allp <- html_text(html_nodes(loty, "p"))
allp <- html_text(html_nodes(loty, "p"))
# Podgląd elementów
all[1]
all <- html_text(html_nodes(loty, "p"))
# Podgląd elementów
all[1]
r
loty <- read_html("http://www.azair.eu/azfin.php?searchtype=flexi&tp=0&isOneway=return&srcAirport=Wroclaw+%5BWRO%5D+%28%2BPOZ%2CKTW%2CPRG%2CKRK%29&srcap1=POZ&srcap2=KTW&srcap5=PRG&srcap9=KRK&srcFreeAirport=&srcTypedText=pra&srcFreeTypedText=&srcMC=&dstAirport=Milan+%5BMXP%5D+%28%2BLIN%2CBGY%29&dstap0=LIN&dstap1=BGY&dstFreeAirport=&dstTypedText=mil&dstFreeTypedText=&dstMC=MIL_ALL&depmonth=201903&depdate=2019-03-20&aid=0&arrmonth=202003&arrdate=2020-03-19&minDaysStay=5&maxDaysStay=8&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&samedep=true&samearr=true&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&autoprice=true&adults=1&children=0&infants=0&maxChng=1&currency=EUR&indexSubmit=Search")
aero_detail <- html_text(html_nodes(loty, ".aeroDetail"))
unq_aero <- unique(aero_detail)
processed <- unlist(lapply(unq_aero, function(x) { unlist(strsplit(x, " "))}))
processed
all <- html_text(html_nodes(loty, "p"))
# Podgląd elementów
all[1]
all[2]
all[3]
all[4]
all[10]
all[11]
all <- html_text(html_nodes(loty, "p"))
all[1]
all[2]
all[3]
all[4]
all[5]
all[6]
all <- html_text(html_nodes(loty, "p"))
l <- strsplit(all[1], " ")
l <- unlist(l)
l <- l[(l != "") & (l != "\n")]
l
d <- data.frame()
d <- rbind(l)
d <- as.data.frame(d)
d <-d[c(-2, -3)]
d
loty <- read_html("http://www.azair.eu/azfin.php?searchtype=flexi&tp=0&isOneway=return&srcAirport=Wroclaw+%5BWRO%5D+%28%2BPOZ%2CKTW%2CPRG%2CKRK%29&srcap1=POZ&srcap2=KTW&srcap5=PRG&srcap9=KRK&srcFreeAirport=&srcTypedText=pra&srcFreeTypedText=&srcMC=&dstAirport=Milan+%5BMXP%5D+%28%2BLIN%2CBGY%29&dstap0=LIN&dstap1=BGY&dstFreeAirport=&dstTypedText=mil&dstFreeTypedText=&dstMC=MIL_ALL&depmonth=201903&depdate=2019-03-20&aid=0&arrmonth=202003&arrdate=2020-03-19&minDaysStay=5&maxDaysStay=8&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&samedep=true&samearr=true&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&autoprice=true&adults=1&children=0&infants=0&maxChng=1&currency=EUR&indexSubmit=Search")
#wczytanie danych
library(rvest)
loty <- read_html("http://www.azair.eu/azfin.php?searchtype=flexi&tp=0&isOneway=return&srcAirport=Wroclaw+%5BWRO%5D+%28%2BPOZ%2CKTW%2CPRG%2CKRK%29&srcap1=POZ&srcap2=KTW&srcap5=PRG&srcap9=KRK&srcFreeAirport=&srcTypedText=pra&srcFreeTypedText=&srcMC=&dstAirport=Milan+%5BMXP%5D+%28%2BLIN%2CBGY%29&dstap0=LIN&dstap1=BGY&dstFreeAirport=&dstTypedText=mil&dstFreeTypedText=&dstMC=MIL_ALL&depmonth=201903&depdate=2019-03-20&aid=0&arrmonth=202003&arrdate=2020-03-19&minDaysStay=5&maxDaysStay=8&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&samedep=true&samearr=true&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&autoprice=true&adults=1&children=0&infants=0&maxChng=1&currency=EUR&indexSubmit=Search")
all <- html_text(html_nodes(loty, "p")) #cos z list_of_variables
loty <- read_html("http://www.azair.eu/azfin.php?tp=0&searchtype=flexi&srcAirport=Denmark+%5BAAR%5D+%28%2BAAL%2CBLL%2CCPH%29&srcTypedText=Den&srcFreeTypedText=&srcMC=DK&srcap0=AAL&srcap1=BLL&srcap2=CPH&srcFreeAirport=&dstAirport=London+%5BLGW%5D+%28%2BLHR%2CLCY%2CSEN%2CLTN%2CSTN%29&dstTypedText=Lon&dstFreeTypedText=&dstMC=LON_ALL&adults=1&children=0&infants=0&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&dstap0=LHR&dstap1=LCY&dstap2=SEN&dstap3=LTN&dstap5=STN&dstFreeAirport=&depdate=23.4.2019&arrdate=31.3.2020&minDaysStay=5&maxDaysStay=8&nextday=0&autoprice=true&currency=EUR&wizzxclub=false&supervolotea=false&schengen=false&transfer=false&samedep=true&samearr=true&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&maxChng=1&isOneway=return&resultSubmit=Search")
all <- html_text(html_nodes(loty, "p")) #cos z list_of_variables
l <- strsplit(all[1], " ")
l <- unlist(l)
l <- l[(l != "") & (l != "\n")]
l
d <- data.frame()
d <- rbind(l)
d <- as.data.frame(d)
d <-d[c(-2, -3)]
d
all[1]
loty <- read_html("http://www.azair.eu/azfin.php?tp=0&searchtype=flexi&srcAirport=Denmark+%5BAAR%5D+%28%2BAAL%2CBLL%2CCPH%29&srcTypedText=Den&srcFreeTypedText=&srcMC=DK&srcap0=AAL&srcap1=BLL&srcap2=CPH&srcFreeAirport=&dstAirport=New+York+%28JFK%29+%5BJFK%5D&dstTypedText=New+York&dstFreeTypedText=&dstMC=&adults=1&children=0&infants=0&minHourStay=0%3A45&maxHourStay=23%3A20&minHourOutbound=0%3A00&maxHourOutbound=24%3A00&minHourInbound=0%3A00&maxHourInbound=24%3A00&dstFreeAirport=&depdate=23.4.2019&arrdate=31.3.2020&minDaysStay=5&maxDaysStay=8&nextday=0&autoprice=true&currency=EUR&wizzxclub=false&supervolotea=false&schengen=false&transfer=false&samedep=true&samearr=true&dep0=true&dep1=true&dep2=true&dep3=true&dep4=true&dep5=true&dep6=true&arr0=true&arr1=true&arr2=true&arr3=true&arr4=true&arr5=true&arr6=true&maxChng=1&isOneway=return&resultSubmit=Search")
all <- html_text(html_nodes(loty, "p")) #cos z list_of_variables
l <- strsplit(all[1], " ")
l <- unlist(l)
l <- l[(l != "") & (l != "\n")]
l
d <- data.frame()
d <- rbind(l)
d <- as.data.frame(d)
d <-d[c(-2, -3)]
d
# Podgląd elementów
all[1]
library(ggplot2)
library(dplyr)
library(ggthemes)
official <- c(6.6, 5.6, 5.6, 5.3, 4.6, 4.3, 4.0, 4.2, 5.7, 5.8,
5.7, 5.3, 4.7, 4.6, 5.0, 7.8, 9.8, 9.1, 8.3, 8.0,
6.6, 5.7, 4.9, 4.8, 4.4, 4.0) / 100
real <- c(11.8, 10.2, 9.8, 9.4, 8.4, 7.7, 7.1, 7.3, 9.5, 10.0,
9.9, 9.3, 8.4, 8.4, 9.2, 14.2, 16.7, 16.2, 15.2, 14.5,
12.7, 11.3, 9.9, 9.4, 8.2, 8.1) /100
unemployment <- data.frame(
Year = c(c(1994:2019), c(1994:2019)),
Rate = c(official, real),
Type = as.factor(c(rep(times = 26, "official"), rep(times = 26, "real")))
)
ggplot(data = unemployment, aes(x = as.factor(Year) , y = Rate, fill = Type)) +
geom_bar(stat = "identity", position = position_dodge(width = 0), width = 1.3) +
scale_y_continuous(labels = scales::percent, expand = expand_scale(add = c(0, 0)), limits = c(0, 0.2)) +
scale_fill_brewer(palette="Paired") +
theme_gray() +
labs(title = "Unemployment rate in USA 1994-2019", x = "Year", y = "Rate", caption =
"Source: https://www.thebalance.com/what-is-the-real-unemployment-rate-3306198") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.4),
panel.grid.minor.y = element_line(colour = "white"), legend.position = "bottom", text = element_text(size=12))
Dzielnice <- c('Bemowo', 'Białołęka', 'Bielany', 'Mokotów', 'Ochota', 'Praga-Południe', 'Praga-Północ',
'Rembertów', 'Śródmieście',  'Targówek', 'Ursus', 'Ursynów', 'Wawer', 'Wesoła', 'Wilanów',
'Włochy', 'Wola', 'Żoliborz')
LiczbaInterwencji <- c(177, 295, 623, 578, 532, 838, 564, 88, 1446, 431, 162, 195, 294, 55, 157, 185, 900, 400)
dane <- data.frame(Dzielnice, LiczbaInterwencji)
dane <- dane %>% mutate(Dzielnica = factor(Dzielnice,levels=rev(unique(Dzielnice))))
dane$Dzielnica <- factor(dane$Dzielnica, levels = dane$Dzielnica[order(dane$LiczbaInterwencji)])
ggplot(data=dane, aes(x=Dzielnica, y=LiczbaInterwencji)) +
scale_x_discrete() +
scale_y_continuous() +
geom_bar(stat='identity', aes(fill = Dzielnica)) +
ggtitle('Liczba interwencji Straży Mijeskiej m.st. Warszawy \n w styczniu 2019 w podziale na dzielnice') +
xlab('Dzielnice') +
ylab('Liczba interwencji')+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
geom_text(aes(label =LiczbaInterwencji, y = LiczbaInterwencji), size = 3)
ggplot(data=dane, aes(x=Dzielnica, y=LiczbaInterwencji)) +
scale_x_discrete() +
scale_y_continuous() +
geom_bar(stat='identity', aes(fill = Dzielnica)) +
ggtitle('Liczba interwencji Straży Mijeskiej m.st. Warszawy \n w styczniu 2019 w podziale na dzielnice') +
xlab('Dzielnice') +
ylab('Liczba interwencji')+
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
geom_text(aes(label =LiczbaInterwencji, y = LiczbaInterwencji), size = 3)
rm(list = ls())
setwd("~/R files/Machine Learning/Projekt 2 - ZMUM")
# Projekt 2
setwd("~/R files/Machine Learning/Projekt 2 - ZMUM")
dat <- read.table('artificial_train.data')
head(dat)
dat <- read.table('artificial_train.data')
dat_labels <- read.table('artificial_train.labels')
# Projekt 2
library(caret)
nzv <- nearZeroVar(dat, saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]
data(mdrr)
data.frame(table(mdrrDescr$nR11))
mdrrClass
head(mdrr)
head(mdrrDescr)
nzv <- nearZeroVar(as.data.frame(dat), saveMetrics= TRUE)
nzv[nzv$nzv,][1:10,]
head(dat)
nzv[nzv$nzv,][1:10,]
descrCor <-  cor(dat)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .999)
highCorr <- sum(abs(descrCor[upper.tri(descrCor)]) > .9)
highCorr
descrCor[upper.tri(descrCor)]
descrCor
descrCor <-  cor(dat)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
highlyCorDescr
highlyCorDescr <- findCorrelation(descrCor, cutoff = .9)
highlyCorDescr
comboInfo <- findLinearCombos(ltfrDesign)
comboInfo <- findLinearCombos(dat)
comboInfo
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
highlyCorDescr
dat[-highlyCorDescr]
dat <- dat[-highlyCorDescr]
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, dat_labels, sbfControl = filterCtrl)
dat <- read.table('artificial_train.data')
dat_labels <- read.table('artificial_train.labels')
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, dat_labels, sbfControl = filterCtrl)
data(mdrr)
mdrrDescr <- mdrrDescr[,-nearZeroVar(mdrrDescr)]
mdrrDescr <- mdrrDescr[, -findCorrelation(cor(mdrrDescr), .8)]
set.seed(1)
filteredNB <- sbf(mdrrDescr, mdrrClass,
sbfControl = sbfControl(functions = nbSBF,
verbose = FALSE,
method = "repeatedcv",
repeats = 5))
library(e1071)
install.packages("e1071")
library(e1071)
filteredNB <- sbf(mdrrDescr, mdrrClass,
sbfControl = sbfControl(functions = nbSBF,
verbose = FALSE,
method = "repeatedcv",
repeats = 5))
install.packages("klaR")
library(klaR)
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, dat_labels, sbfControl = filterCtrl)
mdrrDescr
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
dat <- read.table('artificial_train.data')
dat_labels <- read.table('artificial_train.labels')
descrCor <-  cor(dat)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
highlyCorDescr
dat <- dat[-highlyCorDescr]
comboInfo <- findLinearCombos(dat)
comboInfo
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
str(dat)
str(dat_labels)
str(mdrrClass)
dat_labels <- as.vector.factor(dat_labels)
dat_labels <- read.table('artificial_train.labels')
dat_labels <- as.vector(dat_labels)
str(dat_labels)
dat_labels <- vector(dat_labels)
dat_labels <- dat_labels$V1
dat_labels <- as.factor(dat_labels$V1)
dat_labels <- as.factor(dat_labels)
descrCor <-  cor(dat)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
highlyCorDescr
dat <- dat[-highlyCorDescr]
filterCtrl <- sbfControl(functions = rfSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
rfWithFilter
filterCtrl <- sbfControl(functions = AdaBag, method = "repeatedcv", repeats = 5)
filterCtrl <- sbfControl(functions = rqlasso, method = "repeatedcv", repeats = 5)
?sbfControl
filterCtrl <- sbfControl(functions = AdaSBF, method = "repeatedcv", repeats = 5)
filterCtrl <- sbfControl(functions = treebagSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
rfWithFilter
filterCtrl <- sbfControl(functions = caretSBF, method = "repeatedcv", repeats = 5)
set.seed(10)
rfWithFilter <- sbf(dat, as.factor(dat_labels), sbfControl = filterCtrl)
rfWithFilter
library(mlbench)
library(Hmisc)
library(randomForest)
install.packages("Hmisc")
install.packages("mlbench")
library(mlbench)
library(Hmisc)
subsets <- c(1:5, 10, 15, 20, 25)
ctrl <- rfeControl(functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
set.seed(10)
ctrl <- rfeControl(functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(dat, dat_labels,
sizes = subsets,
rfeControl = ctrl)
lmProfile
dat <- read.table('artificial_train.data')
dat_labels <- read.table('artificial_train.labels')
dat_labels <- dat_labels$V1
dat_labels <- as.factor(dat_labels)
descrCor <-  cor(dat)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
dat <- dat[-highlyCorDescr]
subsets <- c(1:5, 10, 15, 20, 25)
set.seed(10)
ctrl <- rfeControl(functions = lmFuncs,
method = "repeatedcv",
repeats = 5,
verbose = FALSE)
lmProfile <- rfe(dat, dat_labels,
sizes = subsets,
rfeControl = ctrl)
