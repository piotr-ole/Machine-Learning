samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 8)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,40)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 20)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,40)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.5)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.5)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.4)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
?xgboost
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.35)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.4)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.5)
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.5)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.4)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
for (j in seq(2,20)) {
samp <- sample(nrow(dat), replace = FALSE)
dt <- dat[samp, ]
dt_labels <- dat_labels[samp]
bcs_xgb = numeric(cv_num)
acc = numeric(cv_num)
for (i in seq(0, cv_num - 1)) {
ind <- (nsize*i + 1):(nsize*(i+1))
train <- dt[-ind, ]
test <- dt[ind, ]
train_lab <- dt_labels[-ind]
test_lab <- dt_labels[ind]
model.xgb <- xgboost(data = data.matrix(train[, vars_names[1:j]]), label = train_lab,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(test[, vars_names[1:j]]))
predicted_classes_xgb <- ifelse( pred_xgb > 0.5, 1, 0)
bcs_xgb[i + 1] <- balanced_acc(predicted_classes_xgb, test_lab)
t <- table(predicted_classes_xgb, test_lab)
acc[i+1] <- (t[1,1] + t[2,2]) / sum(t)
#print((t[1,1] + t[2,2]) / sum(t))
}
print(paste0(j, ": Balanced accuraccy (xgb) after cross-val: ",mean(bcs_xgb)))
}
setwd("C:/Users/Asus/Documents/Studia IAD/ZMUM/Machine-Learning/FeatureSelection")
# Projekt 2
# libraries & sources
library(caret)
library(e1071)
library(klaR)
library(mlbench)
library(Hmisc)
library(randomForest)
library(devtools)
library(bounceR)
library(xgboost)
library(FSelector)
rm(list = ls())
source("functions.R")
train <- read.table('./data/artificial_train.data')
train_labels <- read.table('./data/artificial_train.labels')
train_labels <- dat_labels$V1
train_labels[dat_labels == -1] = 0
validate <- read.table('./data/artificial_valid.data')
fit_rf = randomForest(as.factor(class) ~. , data=cbind(dat, class = dat_labels))
vars = importance(fit_rf)
vars_names <- rownames(vars)
ord = order(vars, decreasing = TRUE)
vars <- vars[ord]
vars_names <- vars_names[ord]
important_vars <- vars_names[1:15]
model.xgb <- xgboost(data = data.matrix(train[, important_vars]), label = train_labels,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(validate[, important_vars]))
setwd("C:/Users/Asus/Documents/Studia IAD/ZMUM/Machine-Learning/FeatureSelection")
# Projekt 2
# libraries & sources
library(caret)
library(e1071)
library(klaR)
library(mlbench)
library(Hmisc)
library(randomForest)
library(devtools)
library(bounceR)
library(xgboost)
library(FSelector)
rm(list = ls())
source("functions.R")
train <- read.table('./data/artificial_train.data')
train_labels <- read.table('./data/artificial_train.labels')
train_labels <- train_labels$V1
train_labels[train_labels == -1] = 0
validate <- read.table('./data/artificial_valid.data')
fit_rf = randomForest(as.factor(class) ~. , data=cbind(dat, class = dat_labels))
vars = importance(fit_rf)
vars_names <- rownames(vars)
ord = order(vars, decreasing = TRUE)
vars <- vars[ord]
vars_names <- vars_names[ord]
important_vars <- vars_names[1:15]
model.xgb <- xgboost(data = data.matrix(train[, important_vars]), label = train_labels,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(validate[, important_vars]))
setwd("C:/Users/Asus/Documents/Studia IAD/ZMUM/Machine-Learning/FeatureSelection")
# Projekt 2
# libraries & sources
library(caret)
library(e1071)
library(klaR)
library(mlbench)
library(Hmisc)
library(randomForest)
library(devtools)
library(bounceR)
library(xgboost)
library(FSelector)
rm(list = ls())
source("functions.R")
train <- read.table('./data/artificial_train.data')
train_labels <- read.table('./data/artificial_train.labels')
train_labels <- train_labels$V1
train_labels[train_labels == -1] = 0
validate <- read.table('./data/artificial_valid.data')
fit_rf = randomForest(as.factor(class) ~. , data=cbind(train, class = train_labels))
vars = importance(fit_rf)
vars_names <- rownames(vars)
ord = order(vars, decreasing = TRUE)
vars <- vars[ord]
vars_names <- vars_names[ord]
important_vars <- vars_names[1:15]
model.xgb <- xgboost(data = data.matrix(train[, important_vars]), label = train_labels,
objective = 'binary:logistic', verbose = 0, nrounds = 10, eta = 0.3)
pred_xgb <-  predict(model.xgb, newdata = data.matrix(validate[, important_vars]))
head(pred)
head(pred_xgb)
################## BORUTA FEATURE SELECTION ################################
library(Boruta)
install.packages("Boruta")
################## BORUTA FEATURE SELECTION ################################
library(Boruta)
boruta_output <- Boruta(as.factor(class) ~. , data=cbind(dat, class = dat_labels), doTrace=2)
setwd("C:/Users/Asus/Documents/Studia IAD/ZMUM/Machine-Learning/FeatureSelection")
# Projekt 2
# libraries & sources
library(caret)
library(e1071)
library(klaR)
library(mlbench)
library(Hmisc)
library(randomForest)
library(devtools)
library(bounceR)
library(xgboost)
library(FSelector)
rm(list = ls())
source("functions.R")
# Wczytanie danych
dat <- read.table('./data/artificial_train.data')
dat_labels <- read.table('./data/artificial_train.labels')
dat_labels <- dat_labels$V1
dat_labels[dat_labels == -1] = 0
boruta_output <- Boruta(as.factor(class) ~. , data=cbind(dat, class = dat_labels), doTrace=2)
