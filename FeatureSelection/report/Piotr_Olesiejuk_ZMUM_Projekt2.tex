\documentclass{article}
\usepackage
[
a4paper,
left = 2.5cm,
right = 2.5cm
]{geometry}
%\usepackage{lipsum}
\usepackage{polski}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{graphics}
\usepackage{float}
\graphicspath{{./Sprawozdanie5-graphics/}}
\usepackage{amsmath}
\usepackage{nccmath}
\title{RAPORT \\ \ \\ Projekt nr 1}
\author{Piotr Olesiejuk }
\date{\today}

\begin{document}
	\maketitle
\section{Cel projektu}
	Celem projektu było zastosowanie wybranych metod selekcji cech, które zostaną wykorzystane w procesie konstrukcji klasyfikatora.
\section{Miara oceny klasyfikatora}
Miarą przyjętą do oceny jakości klasyfikacji jest balanced accuracy. Sposób jej obliczania jest następujący: \\ \\
\begin{equation}
BA = \frac{1}{2}(\frac{true \ positive}{positive} + \frac{true \ negative}{negative}) 
\end{equation}

\section{Zbiór danych}

Zbiór danych podzielony jest na część treningową oraz walidacyjną. Część treningowa posiada zmienną odpowiedzi, natomiast walidacyjna nie. W poniższej tabeli zebrano ilość rekordów oraz zmiennych z poszczególnych zbiorach:

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Zbiór & Ilość rekordów & Ilość cech \\
			\hline
			treningowy & 2000 & 500 \\
			\hline
			walidacyjny & 600 & 500 \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\section{Testowane algorytmy klasyfikacyjne}
Do konstrukcji klasyfikatorów oraz w procesie selekcji cech wykorzystano następujący zestaw klasyfikatorów:
\begin{enumerate}
	\item las losowy (randomForest)
	\item regresja logistyczna (glm)
	\item xgboost
	\item kNN
\end{enumerate}

\section{Selekcja cech}

\subsection{Pierwsze kroki}

W pierwszym podejściu do danych zastosowano algorytm xgboost bez wykorzystania selekcji cech w celu sprawdzenia jakie balanced accuracy jest osiągalne na całym zbiorze. Jeżeli selekcja cech w dalszej części projektu dałaby gorsze wyniki niż takie podejście, wtedy byłby to punkt wyjścia do stwierdzenia, że nie jest ona przeprowadzona poprawnie. \\
Do testu podzielono zbiór danych na część treningową oraz testową (80/20) i przeprowadzono trening xgboost z wykorzystaniem 5-cio krotnej kroswalidacji.
Balanced accuracy na takim zbiorze wyniósł 79,69\% co oznacza, że każdy gorszy wynik po selekcji cech powinien być oceniony krytycznie.

\subsection{Selekcja cech z wykorzystaniem randomForest}

Jako pierwszą metodę selekcji wybrano wybór cech na podstawie ich istotności  w algorytmie randomForest. W tym celu wytrenowano randomForest na całym zbiorze treningowym i funkcją importance() dokonano sprawdzenia istotności poszczególnych zmiennych. Następnie istotności te zostały posortowane w kolejności malejącej i wybrano z nich 40 pierwszych zmiennych do dalszej części selekcji. \\ \\
W kolejnym kroku przeprowadzono trening i test dla algorytmu xgboost dla różnych zestawów zmiennych objaśniających w taki sposób, że pierwszy trening przeprowadzono dla dwóch najbardziej istotnych zmiennych, a każdy kolejny trening był przeprowadzony na starym zestawie zmiennych objaśniających powiększonym o kolejną, najbardziej istotną zmienną. Przy takim podejściu zostało wybrane 15 najistotniejszych cech. Dokładanie kolejnych cech nie przynosiło znaczącej poprawy BA, powtarzanie testu wykazało, że dalsza poprawa mocno zależy od wstępnego podziału na próbę testową i treningową w kroswalidacji i może wynieść maksymalnie ok. 1 \%, co zdecydowało o pozostawieniu 15 cech.  Wytrenowany na tych zmiennych model wykazał wartość BA = 85,71\%. Poniżej znajduje się tabela podsumowująca opisane podejście wyboru zmiennych. \\

\begin{table}[H]
	\begin{center}
		\begin{tabular}{|l|l|}
			\hline
			Podstawa selekcji & istotność cech w modelu randomForest \\
			\hline
			Klasyfikator & xgboost \\
			\hline
			Ilość wybranych istotnych cech & 15 \\
			\hline
			Balanced accuracy & 85,71\% \\
			\hline
		\end{tabular}
	\end{center}
\end{table}

\section{Pliki programu}
\begin{enumerate}
	\item functions.R - zawiera wszystkie zdefiniowane funkcje wykorzystane w projekcie
	\item projekt.R - zawiera kod, który wykonuje selekcję cech oraz trenowanie modeli
	\item evaluate.R - plik w którym trenowany jest finalny model i dokonywana predykcja na zbiorze walidacyjnym
\end{enumerate}
\end{document}