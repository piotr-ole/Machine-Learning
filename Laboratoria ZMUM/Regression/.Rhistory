X[,1] = hinge_r(X[,1],0)
X[,2] = hinge_r(X[,1],1)
y = X[,1] + X[,2]  + rnorm(n,sd=0.1)
}
if(sim=="4"){
#Example 4:
n = 1000
p = 50
X = matrix(0,ncol=p,nrow=n)
for(j in 1:p) X[,j] = rnorm(n)
y = sin(X[,1])  + rnorm(n,sd=0.1)
}
if(sim=="5"){
#Example 5:
n = 1000
p = 50
X = matrix(0,ncol=p,nrow=n)
for(j in 2:p) X[,j] = rnorm(n)
X[,1]=sort(rnorm(n))
y = ifelse(X[,1]<0,1,0)
}
d=data.frame(X,y)
#Dopasowanie modelu:
model = earth(y~.,data=d,degree=2,trace=3,penalty=0,minspan=0)
#Rownanie modelu:
summary(model, digits = 2, style = "pmax")
#Wykresy Y~X oraz \hat{Y}~X
or1 = order(X[,1])
plot(X[or1,1],y[or1])
lines(X[or1,1],model$fitted.values[or1],type="l",col="red",lwd=2)
#Wykres: Y~\hat{Y}
plot(y[or1],model$fitted.values[or1])
?earth
install.packages("FSelector")
library(FSelector)
n <- 100
p <- 1000
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnom(n, mean = 0, sd = 1)
# Feature Selection
rm(list = ls())
n <- 100
p <- 1000
y <- rnorm(n, mean = 0, sd = 1)
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
dim(x)
max_cor <- max(sapply(x, function(x, y) { cor(x ,y)}, y))
max_cor <- max(sapply(x, function(t, y) { cor(t , y)}, y))
max_cor <- max(sapply(x, function(t, y) { dim(t)}, y))
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(x , y)}, y))
?apply
L <- 100
max_cors <- replicate(L , {
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(x , y)}, y))
return(max_cor)
})
rm(list = ls())
n <- 100
p <- 1000
L <- 100
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cors <- replicate(L , {
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(x , y)}, y))
return(max_cor)
})
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
max_cors <- replicate(L , {
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
return(max_cor)
})
rm(list = ls())
n <- 100
p <- 1000
L <- 100
max_cors <- replicate(L , {
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
return(max_cor)
})
library(ggplot2)
ggplot(data = data.frame(x = rep(1, length(max_cors)),
y = max_cors),
aes(x = x, y = y)) +
geom_boxplot()
p1 <- ggplot(data = data.frame(x = rep(1, length(max_cors)),
y = max_cors),
aes(x = x, y = y)) +
geom_boxplot()
n <- 100
p <- 10000
L <- 100
max_cors <- replicate(L , {
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
return(max_cor)
})
simulation <- function(n, p , L) {
max_cors <- replicate(L , {
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
return(max_cor)
})
p <- ggplot(data = data.frame(x = rep(1, length(max_cors)),
y = max_cors),
aes(x = x, y = y)) +
geom_boxplot()
return(list(max_cors, p))
}
s1 <- simulation(100, 1000, 100)
simulation <- function(n, p , L) {
max_cors <- replicate(L , {
x <- matrix( rnorm(n * p, mean = 0, sd = 1), nrow = n, ncol = p )
y <- rnorm(n, mean = 0, sd = 1)
max_cor <- max(apply(x, MARGIN = 2, FUN = function(t, y) { cor(t , y)}, y))
return(max_cor)
})
p <- ggplot(data = data.frame(x = rep(1, length(max_cors)),
y = max_cors),
aes(x = x, y = y)) +
geom_boxplot()
return(list(corelations = max_cors, boxplot = p))
}
s1 <- simulation(100, 1000, 100)
s1$boxplot
s2 <- simulation(100, 10000, 100)
s2$boxplot
s3 <- simulation(100, 50000, 100)
rbinom(1, 10, 0.5)
rbinom(10, 11, 0.5)
rbinom(10, 1, 0.5)
sum(rbinom(100, 1, 0.5))
sum(rbinom(1000, 1, 0.5))
sum(rbinom(10000, 1, 0.5))
sum(rbinom(100000, 1, 0.5))
sum(rbinom(1000000, 1, 0.5))
sum(rbinom(10000000, 1, 0.5))
generate_pair <- function(choice, sigm) {
eps = rnorm(n, mean = 0, sd = sigm)
if (choice == '1') {
x <- runif(n = n , min = 0, max = 1)
y <- 2 * x + eps
} else if (choice == '2') {
x <- runif(n = n , min = 0, max = 1)
y <-  rbinom(n, 1, 0.5) * sqrt(x) + eps
} else if (choice == '3') {
x <- runif(n = n , min = -1, max = 1)
y <- x^2 + eps
} else if (choice == '4') {
x <- runif(n = n , min = 0, max = 6)
y <- sin(x) + eps
}
return(list(x, y))
}
choice = '1'
L <- 50
corelations <- list()
i = 1
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
corelations[[i]] = mean(cors)
i = i + 1
}
generate_pair <- function(choice, sigm) {
eps = rnorm(n, mean = 0, sd = sigm)
if (choice == '1') {
x <- runif(n = n , min = 0, max = 1)
y <- 2 * x + eps
} else if (choice == '2') {
x <- runif(n = n , min = 0, max = 1)
y <-  rbinom(n, 1, 0.5) * sqrt(x) + eps
} else if (choice == '3') {
x <- runif(n = n , min = -1, max = 1)
y <- x^2 + eps
} else if (choice == '4') {
x <- runif(n = n , min = 0, max = 6)
y <- sin(x) + eps
}
return(list(x, y))
}
set <- generate_pair('1', 1)
set$x
generate_pair <- function(choice, sigm) {
eps = rnorm(n, mean = 0, sd = sigm)
if (choice == '1') {
x <- runif(n = n , min = 0, max = 1)
y <- 2 * x + eps
} else if (choice == '2') {
x <- runif(n = n , min = 0, max = 1)
y <-  rbinom(n, 1, 0.5) * sqrt(x) + eps
} else if (choice == '3') {
x <- runif(n = n , min = -1, max = 1)
y <- x^2 + eps
} else if (choice == '4') {
x <- runif(n = n , min = 0, max = 6)
y <- sin(x) + eps
}
return(list(x = x, y = y))
}
set <- generate_pair('1', 1)
set$x
choice = '1'
L <- 50
corelations <- list()
i = 1
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
corelations[[i]] = mean(cors)
i = i + 1
}
plot(seq(0, 5, by = 0.1), corelations)
?information.gain
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
infgs <- replicate(L,
{
set <- generate_pair(choice, s)
df <- data.frame(y = set$y, x = set$x)
return(information.gain(y ~ x, df))
})
inf.gains[[i]] = mean(infgs)
corelations[[i]] = mean(cors)
i = i + 1
}
#3
set <- generate_pair(choice = '1', s = 1)
df <- data.frame(y = set$y, x = set$x)
return(information.gain(y ~ x, df))
information.gain(y ~ x, df)
as.numeric(information.gain(y ~ x, df))
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
infgs <- replicate(L,
{
set <- generate_pair(choice, s)
df <- data.frame(y = set$y, x = set$x)
return(as.numeric(information.gain(y ~ x, df)))
})
inf.gains[[i]] = mean(infgs)
corelations[[i]] = mean(cors)
i = i + 1
}
plot(seq(0, 5, by = 0.1), corelations)
choice = '1'
L <- 50
corelations <- list()
inf.gains <- list()
i = 1
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
infgs <- replicate(L,
{
set <- generate_pair(choice, s)
df <- data.frame(y = set$y, x = set$x)
return(as.numeric(information.gain(y ~ x, df)))
})
inf.gains[[i]] = mean(infgs)
corelations[[i]] = mean(cors)
i = i + 1
}
plot(seq(0, 5, by = 0.1), corelations)
plot(seq(0, 5, by = 0.1), inf.gains)
n <- 100
x <- runif(n, min = 0, max = 10)
n <- 100
x <- runif(n, min = 0, max = 10)
y <- runif(n, min = 0, max = 10)
plot(x,y)
cor(x,y)
n <- 100
x <- runif(n, min = 0, max = 10)
y <- runif(n, min = 0, max = 1)
plot(x,y)
cor(x,y)
x <- runif(n, min = 0, max = 10)
y <- x + rnorm(n, 0, 0.1)
plot(x,y)
cor(x,y)
y <- x + rnorm(n, 0, 0.01)
plot(x,y)
x <- runif(n, min = 0, max = 10)
y <- x + rnorm(n, 0, 0.01)
plot(x,y)
cor(x,y)
y <- x + rnorm(n, 0, 1)
plot(x,y)
cor(x,y)
choice = '1'
L <- 50
corelations <- list()
inf.gains <- list()
i = 1
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
infgs <- replicate(L,
{
set <- generate_pair(choice, s)
df <- data.frame(y = set$y, x = set$x)
return(as.numeric(information.gain(y ~ x, df)))
})
inf.gains[[i]] = mean(infgs)
corelations[[i]] = mean(cors)
i = i + 1
}
plot(seq(0, 5, by = 0.1), corelations)
plot(seq(0, 5, by = 0.1), inf.gains)
plot(seq(0, 5, by = 0.1), corelations)
choice = '2'
L <- 50
corelations <- list()
inf.gains <- list()
i = 1
for (s in seq(0 ,5, by = 0.1)) {
cors <- replicate(L,
{
set <- generate_pair(choice, s)
cor(set$x, set$y)
})
infgs <- replicate(L,
{
set <- generate_pair(choice, s)
df <- data.frame(y = set$y, x = set$x)
return(as.numeric(information.gain(y ~ x, df)))
})
inf.gains[[i]] = mean(infgs)
corelations[[i]] = mean(cors)
i = i + 1
}
plot(seq(0, 5, by = 0.1), corelations)
plot(seq(0, 5, by = 0.1), inf.gains)
plot(seq(0, 5, by = 0.1), corelations)
## Zadanie 3
n <- 100
p <- 1000
x <- rnorm(p, mean = 0, sd = 1)
c(1,2,3) * c(1,3, 5)
## Zadanie 3
n <- 100
p <- 1000
x <- rnorm(p, mean = 0, sd = 1)
beta <-  c(1,1,1, rep(0, p - 3))
p <- 1 / (1 + exp(- beta * x))
rbinom(1,10)
rbinom(1,10, 0.5)
y <- rbinom(n, 1, p)
library(glmnet)
instal.packages('glmnet')
install.packages('glmnet')
library(glmnet)
?cv.glmnet
n = 1000
p = 500
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
model = glmnet(x, y, family = 'binomial')
model
model$lambda
#Wybor optymalnego parametru lambda:
cv.glmnet1 = cv.glmnet(x,y,family="binomial")
lambda_opt = cv.glmnet1$lambda.1se
lambda_opt
model$beta
wspolczynniki = model$beta[,which(model$lambda==lambda_opt)]
wspolczynniki
est_true = which(wspolczynniki!=0)
est_true
recall = length(intersect(true,est_true))/length(true)
prec = length(intersect(true,est_true))/length(est_true)
print(recall)
print(prec)
?step
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(x, y, family = 'binomial')
?glm
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ x, data = list(x,y) family = 'binomial')
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ x, data = list(x,y), family = 'binomial')
n = 1000
p = 500
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
head(d)
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ ., data = d, family = 'binomial')
# METODA MULTISPLIT
library(hdi)
# METODA MULTISPLIT
install.packages('hdi')
library(hdi)
n = 200
p = 50
coef1 = numeric(100)
cat("Simulation",k,"\n")
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
model = glm(y~.,data=d,family="binomial")
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ ., data = d, family = 'binomial')
n = 1000
p = 500
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
n = 1000
p = 500
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ ., data = d, family = 'binomial')
n = 200
p = 50
coef1 = numeric(100)
at("Simulation",k,"\n")
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
model = glm(y~.,data=d,family="binomial")
n = 1000
p = 500
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ ., data = d, family = 'binomial')
n = 200
p = 50
true = c(1,2,3) # indeksy istotnych zmiennych:
x = matrix(0,nrow=n,ncol=p)
for(j in 1:p)x[,j]=rnorm(n)
b=numeric(p)
b[1:3] = 1
eta = x%*%b
probs = exp(eta)/(1+exp(eta))
y = rbinom(n,1,probs)
d = data.frame(x,y)
# METODA KROKOWEGO DOLACZANIA ZMIENNYCH
model = glm(y ~ ., data = d, family = 'binomial')
